{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stein's Phenomenon\n",
    "\n",
    "Stein (1956) found that if the dimension of data $p>=3$, then the MLE estimator $\\hat{\\mu_n}$ is inadmissible. This property is known as **_Stein's phenomenon_**.\n",
    "\n",
    "We start with definition of inadmissible estimators.\n",
    "\n",
    "&emsp;&emsp;**DEFINITION** (Inadmissible)\n",
    "\n",
    "> An estimator $\\hat{\\mu_n}$ of the parameter $\\mu$ is called **_inadmissible_** on $R^p$ with respect to the squared risk if there exists another estimator $\\mu_n^*$ such that\n",
    "$$E||\\mu_n^*-\\mu ||^2\\leq E||\\hat{\\mu}_n-\\mu||^2\\quad\\quad \\textit{for all }\\mu\\in R^p,$$\n",
    "and there exists $\\mu_0\\in R^p$ such that\n",
    "$$E||\\mu_n^*-\\mu_0 ||^2 < E||\\hat{\\mu}_n-\\mu_0||^2.$$\n",
    "\n",
    "&emsp;&emsp;In this case, we also call that $\\mu_n^*$ dominates $\\hat{\\mu}_n$ . Otherwise, the estimator $\\hat{\\mu_n}$ is called admissible. An estimator is admissible if it is not systematically outperformed, i.e. if there does not exist another estimator which displays less error for all the underlying unknown parameters.\n",
    "\n",
    "According to the difinition, Stein's phenomenon can be desribed like:\n",
    "\n",
    "&emsp;&emsp;For $p>=3$, there exists $\\hat{\\mu}$ such that $\\forall\\mu$,\n",
    "$$E||\\hat{\\mu}_n-\\mu ||^2 < E||\\hat{\\mu}^{MLE}_n-\\mu_0||^2,$$\n",
    "which makes MLE inadmissible.\n",
    "\n",
    "A typical choice is the James-Stein estimator given by James-Stein (1961) for Gaussian distribution. To state formally,\n",
    "\n",
    "&emsp;&emsp;**THEOREM**\n",
    "\n",
    "> Suppose there is only one single observation $Y\\thicksim N_p(\\mu,I_p)$ (we want to estimate $\\mu$). Then $\\hat{\\mu}^{MLE}=Y$. \n",
    "> Define\n",
    "$$\\hat{\\mu}^{JS}_n=(1-\\frac{(p-2)}{||Y||^2})Y,$$\n",
    "> then\n",
    "$$E_{\\mu}||\\hat{\\mu}^{JS}-\\mu||^2<E_{\\mu}||Y-\\mu||^2=E_{\\mu}||\\hat{\\mu}^{MLE}-\\mu||^2.$$\n",
    "\n",
    "Here, we use Monte Carlo simulation to verify this.\n",
    "\n",
    "For simplicity, we assume $\\mu=e_1$, where $e_1$ is the basis vector in which only the first element is 1. Define the following function which takes dimension $p$ and number of simulation `nsim` as inputs to calculate the Monte Carlo simulation results of James Stein estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def JamesStein_vs_MLE_MC(p,nsim):\n",
    "    mean=np.append(1.0,np.zeros((1,p-1)))\n",
    "    cov=np.identity(p)\n",
    "    sample=np.random.multivariate_normal(mean, cov, nsim)\n",
    "    \n",
    "    # mle risk\n",
    "    mle_err=sample-mean\n",
    "    risk_mle=np.linalg.norm(mle_err,axis=1)\n",
    "    risk_mle=np.mean(risk_mle)\n",
    "    print 'Squared error loss for MLE:',risk_mle\n",
    "    \n",
    "    # js risk\n",
    "    shrnk_coef=1-(np.linalg.norm(sample,axis=1))**(-1)*(p-2)\n",
    "    shrnk_coef=np.diag(shrnk_coef)\n",
    "    js_est=np.mat(shrnk_coef)*np.mat(sample)\n",
    "    js_err=js_est-mean\n",
    "    risk_js=np.linalg.norm(js_err,axis=1)\n",
    "    risk_js=np.mean(risk_js)\n",
    "    print 'Squared error loss for James-Stein estimator:',risk_js\n",
    "    return risk_mle, risk_js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared error loss for MLE: 1.18643632116\n",
      "Squared error loss for James-Stein estimator: 1.18643632116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.1864363211590541, 1.1864363211590541)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JamesStein_vs_MLE_MC(2,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we fix the number of simulation(e.g. `nsim=20`) and increase the dimension $p$ to compare the risks for MLE and JS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
